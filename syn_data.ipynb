{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "- Sample multiple prefixes from pile-10k (could do pile later on)\n",
    "- Randomly prepend many random sequence of tokens to the prefix and sample the next token for each one\n",
    "- Take all tokens that had a 10e-6 probability *from just the prefix* and save them to a list\n",
    "- Find cases in the dataset completions where low probability tokens existed, and save them to the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"NeelNanda/pile-10k\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-160m\")\n",
    "rev_model = GPTNeoXForCausalLM.from_pretrained(\"afterless/reverse-pythia-160m\")\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/pythia-160m\", cache_dir=\".cache/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[\"train\"]\n",
    "PREFIX_LENGTH = 20\n",
    "EXAMPLES = 10\n",
    "REPEAT = 10_000\n",
    "EXTRA_TOKENS = 2\n",
    "\n",
    "testSet = {}\n",
    "indices = t.randperm(len(data))[:EXAMPLES].tolist()\n",
    "\n",
    "for i in indices[:2]:\n",
    "    key = t.cat([t.randint(0, tokenizer.vocab_size, (REPEAT, EXTRA_TOKENS)), tokenizer.encode(data[i][\"text\"][:PREFIX_LENGTH], return_tensors=\"pt\").repeat(REPEAT, 1)], dim=-1)\n",
    "    out = model.generate(key, do_sample=False, num_beams=1, max_length=key.shape[1]+1)[:, -1] # (REPEAT, 1)\n",
    "    freqs = t.bincount(out, minlength=tokenizer.vocab_size)\n",
    "    probs = freqs / freqs.sum() \n",
    "    lowProbs = ((0 < probs) & (probs <= 10e-6)).nonzero()\n",
    "    tmp = t.cat([key, out.unsqueeze(1)], dim=-1)\n",
    "    testSet[i] = t.empty((0, tmp.shape[1]), dtype=t.long)\n",
    "    for r in tmp:\n",
    "        if r[-1] in lowProbs:\n",
    "            testSet[i] = t.cat([testSet[i], r.unsqueeze(0)], dim=0)\n",
    "\n",
    "testSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowProbs = {}\n",
    "for i in indices[:3]:\n",
    "    inputs = tokenizer(data[i][\"text\"][:PREFIX_LENGTH], return_tensors=\"pt\")\n",
    "    out = model(**inputs)\n",
    "    probs = t.softmax(out.logits[0, -1], dim=-1)\n",
    "    lowProbs[i] = ((0 < probs) & (probs <= 10e-6)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5310: tensor([[39618, 44333,    18,   537, 12276,  1712,    84,    84]]),\n",
       " 8467: tensor([[22806, 32767, 42353,  5171,  4632,    15, 50178,    93],\n",
       "         [44360, 44740, 42353,  5171,  4632,    15, 50178,  1738],\n",
       "         [19638, 35953, 42353,  5171,  4632,    15, 50178,    94],\n",
       "         [31600, 35138, 42353,  5171,  4632,    15, 50178,   696],\n",
       "         [ 1425,  7224, 42353,  5171,  4632,    15, 50178,    94],\n",
       "         [21647, 46768, 42353,  5171,  4632,    15, 50178,   870],\n",
       "         [46612, 11126, 42353,  5171,  4632,    15, 50178, 15440],\n",
       "         [41602,  3122, 42353,  5171,  4632,    15, 50178,  1738]]),\n",
       " 1647: tensor([], size=(0, 11), dtype=torch.int64)}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = {}\n",
    "for i in indices[:3]:\n",
    "    s = testSet[i]\n",
    "    res[i] = t.empty((0, s.shape[1]), dtype=t.long)\n",
    "    for r in s:\n",
    "        if r[-1] in lowProbs[i]:\n",
    "            res[i] = t.cat([res[i], r.unsqueeze(0)], dim=0)\n",
    "\n",
    "del testSet, lowProbs\n",
    "gc.collect()\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
