{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir_list = os.chdir('./../reverse-dynamics-nlp/')\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, GPTNeoXForCausalLM\n",
    "from prompt_optimizer import PromptOptimizer\n",
    "from utils import get_reverse_pair, start_chunk_hf, forward_loss, reverse_tokenize\n",
    "from utils import reverse_normalized_generate, reverse_normalized_beam_generate, forward_loss_batch, rand_init\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load positional probs\n",
    "sum_of_matrices = None\n",
    "for i in range(30):  \n",
    "    num = str(i).zfill(2)  # pad single digit numbers with a leading zero\n",
    "    file_path = f'/home/jp6263/reverse-dynamics-nlp/pos_counts_10_{num}.pt'\n",
    "    matrix = torch.load(file_path)\n",
    "    \n",
    "    if sum_of_matrices is None:\n",
    "        sum_of_matrices = matrix\n",
    "    else:\n",
    "        sum_of_matrices += matrix\n",
    "\n",
    "# Initialize probabilities\n",
    "completed_sum = sum_of_matrices.clone()\n",
    "completed_sum[completed_sum == 0] = 1\n",
    "\n",
    "completed_sum = sum_of_matrices.clone()\n",
    "completed_sum[completed_sum == 0] = 1\n",
    "\n",
    "inverse_dataset_probabilities = completed_sum.clone()\n",
    "for col in range(inverse_dataset_probabilities.shape[1]):\n",
    "    inverse_dataset_probabilities[:,col] = inverse_dataset_probabilities[:,col] / inverse_dataset_probabilities[:,col].sum()\n",
    "inverse_dataset_probabilities = 1/inverse_dataset_probabilities\n",
    "inverse_dataset_probabilities[50277:] = 1\n",
    "inverse_dataset_probabilities[:2] = 1\n",
    "\n",
    "\n",
    "\n",
    "positionless_inverse_probabilities = completed_sum.clone()\n",
    "positionless_inverse_probabilities = positionless_inverse_probabilities.sum(dim=1)\n",
    "positionless_inverse_probabilities = positionless_inverse_probabilities / positionless_inverse_probabilities.sum()\n",
    "positionless_inverse_probabilities = 1/positionless_inverse_probabilities\n",
    "positionless_inverse_probabilities = positionless_inverse_probabilities.unsqueeze(1).repeat(1, completed_sum.shape[1])\n",
    "positionless_inverse_probabilities[50277:] = 1\n",
    "positionless_inverse_probabilities[:2]=1\n",
    "positionless_inverse_probabilities.shape\n",
    "\n",
    "total_obs = torch.sum(completed_sum)\n",
    "vocab_counts_alpha = completed_sum.sum(dim=1)\n",
    "vocab_counts_beta = total_obs-vocab_counts_alpha\n",
    "vocab_counts_beta = vocab_counts_beta + 5e4\n",
    "\n",
    "positional_alpha = torch.zeros_like(completed_sum)\n",
    "positional_beta = torch.zeros_like(completed_sum)\n",
    "positional_alpha = vocab_counts_alpha.unsqueeze(1).repeat(1, completed_sum.shape[1])+completed_sum\n",
    "positional_beta = vocab_counts_beta.unsqueeze(1).repeat(1, completed_sum.shape[1])+total_obs/10-completed_sum\n",
    "smoothed_positional_inverse_probabilities = (positional_alpha-1)/(positional_alpha+positional_beta-2)\n",
    "smoothed_positional_inverse_probabilities = 1/smoothed_positional_inverse_probabilities\n",
    "smoothed_positional_inverse_probabilities[50277:,:] = torch.ones_like(smoothed_positional_inverse_probabilities[50277:,:])\n",
    "smoothed_positional_inverse_probabilities[:2,:] = torch.ones_like(smoothed_positional_inverse_probabilities[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"afterless/reverse-pythia-160m\")\n",
    "bwd_model = GPTNeoXForCausalLM.from_pretrained(\"afterless/reverse-pythia-160m\").cuda()\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/pythia-160m\", cache_dir='/scratch/jp6263/hf/models/').cuda()\n",
    "tokenizer.eos_token = '<|endoftext|>'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# pile_test = load_dataset(path='/vast/work/public/ml-datasets/pile/', data_files='/vast/work/public/ml-datasets/pile/test.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nanda dataset\n",
    "dataset = load_dataset(\"NeelNanda/pile-10k\")\n",
    "pairs = get_reverse_pair(dataset['train'], start_chunk_hf, tokenizer)\n",
    "print(next(pairs))\n",
    "nanda_list = list(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define plotting functions\n",
    "# Define plot GCG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def plot_gcg_pareto(all_losses, all_naturals, beam_size,):\n",
    "    suffix_loss_mat = -1*np.array(all_losses).T\n",
    "    prefix_loss_mat = -1*np.array(all_naturals).T\n",
    "    mean_prefix_losses = np.mean(prefix_loss_mat, axis=0)\n",
    "    prefix_error = get_errors(prefix_loss_mat, mean_prefix_losses, beam_size)\n",
    "    mean_suffix_losses = np.mean(suffix_loss_mat, axis=0)\n",
    "    suffix_errors = get_errors(suffix_loss_mat, mean_suffix_losses, beam_size)\n",
    "\n",
    "# Plotting\n",
    "    plt.figure()\n",
    "    plt.plot(mean_prefix_losses, mean_suffix_losses, marker='o', label='Best-of-N')\n",
    "    plt.errorbar(mean_prefix_losses, mean_suffix_losses, yerr=suffix_errors, xerr=prefix_error, alpha=0.25, color='red')\n",
    "    plt.plot([mean_prefix_losses[0]], [mean_suffix_losses[0]], marker='x', linestyle='', color='red', label='Greedy Prefix')\n",
    "    plt.xlabel(f'log P(p)')\n",
    "    plt.ylabel('log P(s|p)')\n",
    "    # plt.title(f'Num beams varies from 1 to {beam_size}, mean over {eval_size} samples')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Define plot beams\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def plot_beams(all_losses, all_naturals, beam_size, normalizer_temp, base_prefix_loss=None, base_suffix_loss=None, probs=False):\n",
    "    eval_size = len(all_losses)\n",
    "    print(f'inverse dataset probs temp is {normalizer_temp}')\n",
    "\n",
    "    prefix_loss_at_n, best_suffix_loss_at_n = [[loss[0]] for loss in all_naturals], [[loss[0]] for loss in all_losses]\n",
    "\n",
    "    # For each beam check iterate over all samples and check whether the loss on that beam+sample improved over previous best on that sample.\n",
    "    for n in range(beam_size):\n",
    "        if n == 0:\n",
    "            continue\n",
    "        for l,loss_list in enumerate(all_losses):\n",
    "            next_suffix_loss = loss_list[n]\n",
    "            if next_suffix_loss < best_suffix_loss_at_n[l][-1]:\n",
    "                best_suffix_loss_at_n[l].append(next_suffix_loss)\n",
    "                prefix_loss_at_n[l].append(all_naturals[l][n])\n",
    "            else:\n",
    "                best_suffix_loss_at_n[l].append(best_suffix_loss_at_n[l][-1])\n",
    "                prefix_loss_at_n[l].append(prefix_loss_at_n[l][-1])\n",
    "    \n",
    "    suffix_loss_mat = -1*np.array(best_suffix_loss_at_n)\n",
    "    prefix_loss_mat = -1*np.array(prefix_loss_at_n)\n",
    "    if probs:\n",
    "        suffix_loss_mat = np.exp(-suffix_loss_mat)\n",
    "        prefix_loss_mat = np.exp(-prefix_loss_mat)\n",
    "    mean_prefix_losses = np.mean(prefix_loss_mat, axis=0)\n",
    "    prefix_error = get_errors(prefix_loss_mat, mean_prefix_losses, beam_size)\n",
    "    mean_suffix_losses = np.mean(suffix_loss_mat, axis=0)\n",
    "    suffix_errors = get_errors(suffix_loss_mat, mean_suffix_losses, beam_size)\n",
    "\n",
    "# Plotting\n",
    "    print(f'Losses best and worse are {mean_suffix_losses[0]} and {mean_suffix_losses[-1]}')\n",
    "    print(f'Best has CI {(mean_suffix_losses[-1]-suffix_errors[:,-1][0],mean_suffix_losses[-1]+suffix_errors[:,-1][1])}')\n",
    "    plt.figure()\n",
    "    plt.plot(mean_prefix_losses, mean_suffix_losses, marker='o', label='Best-of-N')\n",
    "    plt.errorbar(mean_prefix_losses, mean_suffix_losses, yerr=suffix_errors, xerr=prefix_error, alpha=0.25, color='red')\n",
    "    plt.plot([mean_prefix_losses[0]], [mean_suffix_losses[0]], marker='x', linestyle='', color='red', label='Greedy Prefix')\n",
    "    if base_prefix_loss is not None:\n",
    "        plt.plot([base_prefix_loss], [base_suffix_loss], marker='s', linestyle='', color='green', label='Dataset Prefix')\n",
    "    plt.xlabel(f'log P(p)')\n",
    "    plt.ylabel('log P(s|p)')\n",
    "    # plt.title(f'Num beams varies from 1 to {beam_size}, mean over {eval_size} samples')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Define plot combo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def get_errors(loss_mat, means, beam_size, exp=True):\n",
    "    bars = []\n",
    "    def multi_arg_mean(*args):\n",
    "        data = np.array(args)\n",
    "        if exp:\n",
    "            return np.exp(np.mean(data))\n",
    "        else:\n",
    "            return np.mean(data)\n",
    "    for n_beam in range(beam_size): \n",
    "        bootstrap = stats.bootstrap((loss_mat[:,n_beam],), statistic=multi_arg_mean, confidence_level=0.95).confidence_interval\n",
    "        if n_beam==0: print(bootstrap)\n",
    "        bars.append([means[n_beam]-bootstrap[0],bootstrap[1]-means[n_beam]])\n",
    "    bars = np.array(bars).T\n",
    "    return bars\n",
    "\n",
    "def exponentiate(list_of_lists):\n",
    "    return [[np.exp(-1*x) for x in l] for l in list_of_lists]\n",
    "\n",
    "def plot_comparison(gcg_losses, gcg_naturals, all_losses, all_naturals, beam_size, gcg_hp_count, base_prefix_loss=None, base_suffix_loss=None, spacing=True):\n",
    "    gcg_suffix_loss_mat = -1*np.array(gcg_losses).T\n",
    "    gcg_prefix_loss_mat = np.array(gcg_naturals).T\n",
    "    gcg_mean_prefix_losses = np.exp(np.mean(gcg_prefix_loss_mat, axis=0))\n",
    "    gcg_prefix_error = get_errors(gcg_prefix_loss_mat, gcg_mean_prefix_losses, gcg_hp_count, exp=True)\n",
    "    gcg_mean_suffix_losses = np.exp(np.mean(gcg_suffix_loss_mat, axis=0))\n",
    "    gcg_suffix_errors = get_errors(gcg_suffix_loss_mat, gcg_mean_suffix_losses, gcg_hp_count, exp=True)\n",
    "\n",
    "    prefix_loss_at_n, best_suffix_loss_at_n = [[loss[0]] for loss in all_naturals], [[loss[0]] for loss in all_losses]\n",
    "    # For each beam check iterate over all samples and check whether the loss on that beam+sample improved over previous best on that sample.\n",
    "    for n in range(beam_size):\n",
    "        if n == 0:\n",
    "            continue\n",
    "        for l,loss_list in enumerate(all_losses):\n",
    "            next_suffix_loss = loss_list[n]\n",
    "            if next_suffix_loss < best_suffix_loss_at_n[l][-1]:\n",
    "                best_suffix_loss_at_n[l].append(next_suffix_loss)\n",
    "                prefix_loss_at_n[l].append(all_naturals[l][n])\n",
    "            else:\n",
    "                best_suffix_loss_at_n[l].append(best_suffix_loss_at_n[l][-1])\n",
    "                prefix_loss_at_n[l].append(prefix_loss_at_n[l][-1])\n",
    "    \n",
    "    suffix_loss_mat = -1*np.array(best_suffix_loss_at_n)\n",
    "    prefix_loss_mat = np.array(prefix_loss_at_n)\n",
    "    mean_prefix_losses = np.exp(np.mean(prefix_loss_mat, axis=0))\n",
    "    prefix_error = get_errors(prefix_loss_mat, mean_prefix_losses, beam_size, exp=True)\n",
    "    mean_suffix_losses = np.exp(np.mean(suffix_loss_mat, axis=0))\n",
    "    suffix_errors = get_errors(suffix_loss_mat, mean_suffix_losses, beam_size, exp=True)\n",
    "\n",
    "# Plotting GCG\n",
    "    plt.figure()\n",
    "    plt.plot(gcg_mean_prefix_losses, gcg_mean_suffix_losses, marker='o', label='GCG with varying prefix loss penalty')\n",
    "    plt.errorbar(gcg_mean_prefix_losses, gcg_mean_suffix_losses, yerr=gcg_suffix_errors, xerr=gcg_prefix_error, alpha=0.25, color='red')\n",
    "    if base_prefix_loss is not None:\n",
    "        plt.plot([base_prefix_loss], [base_suffix_loss], marker='D', linestyle='', color='orange', label='Dataset Prefix')\n",
    "\n",
    "    #RLM\n",
    "    if spacing:\n",
    "        max_idx = len(mean_prefix_losses) - 1\n",
    "        indices = [0]+[int(2**i) for i in range(int(np.log2(max_idx)) + 1) if 2**i <= max_idx]\n",
    "        if max_idx not in indices: indices.append(max_idx)\n",
    "    else:\n",
    "        indices = range(len(mean_prefix_losses))\n",
    "\n",
    "    # Plot using the exponential indices\n",
    "    plt.plot([mean_prefix_losses[i] for i in indices], [mean_suffix_losses[i] for i in indices], marker='v', label='Reverse LM varying number of beams')\n",
    "    plt.errorbar([mean_prefix_losses[i] for i in indices], [mean_suffix_losses[i] for i in indices], yerr=np.array([suffix_errors[:,i] for i in indices]).T, xerr=np.array([prefix_error[:,i] for i in indices]).T, alpha=0.25, color='red')\n",
    "\n",
    "    # plt.plot(mean_prefix_losses[::spacing], mean_suffix_losses[::spacing], marker='v', label='Reverse LM varying number of beams')\n",
    "    # plt.errorbar(mean_prefix_losses[::spacing], mean_suffix_losses[::spacing], yerr=suffix_errors[:,::spacing], xerr=prefix_error[:,::spacing], alpha=0.15, color='red')\n",
    "    plt.plot([mean_prefix_losses[0]], [mean_suffix_losses[0]], marker='x', linestyle='', color='green', label='Greedy Prefix')\n",
    "    plt.xlabel('Perplexity on generated prefixes')#('$log \\ log \\ P(x_{:m})$')\n",
    "    plt.ylabel('Elicitation probability for target suffix')#('$log \\ P(x_{m:n}|x_{:m})$')\n",
    "    plt.xscale('log')\n",
    "    # plt.title(f'Num beams varies from 1 to {beam_size}, mean over {eval_size} samples')\n",
    "    plt.legend(loc='lower left')#'best')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pareto eval RLM\n",
    "beam_size = 50 \n",
    "p_matrix = inverse_dataset_probabilities\n",
    "found_prefixes = []\n",
    "test_set = nanda_list#long_synthetic_list #nanda_list\n",
    "eval_size = 500 #len(entropy_list)#250\n",
    "len_prefix = 10\n",
    "len_suffix=40\n",
    "\n",
    "for normalizer_temp in [0]:#,0.2,.6,1]:\n",
    "    dataset_gold_loss = []\n",
    "    all_losses, all_naturals = [], []\n",
    "    base_losses, base_naturals = [], []\n",
    "    normalizer = p_matrix**normalizer_temp #inverse_dataset_probabilities\n",
    "    for p,pair in enumerate(tqdm(test_set[:eval_size])):\n",
    "        prefix_tokens = tokenizer.encode(pair[0])\n",
    "        suffix_tokens = tokenizer.encode(pair[1])\n",
    "        # if len(prefix_tokens)<len_prefix or len(suffix_tokens)<len_suffix: continue\n",
    "        prefix_loss,suffix_loss = forward_loss(model, pair, tokenizer)\n",
    "        base_losses.append(suffix_loss.item())\n",
    "        base_naturals.append(prefix_loss.item())\n",
    "        # if suffix_loss>2.1: continue #this is around 10th percentile of losses for 170m\n",
    "        prefix, suffix = pair\n",
    "        prefix_tokens = tokenizer.encode(prefix)\n",
    "        all_losses.append([])\n",
    "        all_naturals.append([])\n",
    "        base_losses.append(prefix_loss.item())\n",
    "        \n",
    "        prefix_list = reverse_normalized_beam_generate(bwd_model, tokenizer, suffix, len_prefix, beam_size=beam_size, normalizer=normalizer,)  #reverse_fwd_beam_generate(bwd_model, model, tokenizer, suffix, len_prefix, beam_size=beam_size, normalizer=normalizer,) \n",
    "        pairs_batch = torch.stack(prefix_list)\n",
    "        pairs_batch = torch.cat((pairs_batch, torch.tensor([suffix_tokens]*len(prefix_list))), dim=1)\n",
    "\n",
    "        # Call the batched loss function\n",
    "        predicted_prefix_loss_batch, predicted_suffix_loss_batch = forward_loss_batch(model, pairs_batch, tokenizer, prefix_len=len_prefix,)        \n",
    "        best_prefix = prefix_list[torch.argmin(predicted_suffix_loss_batch)]\n",
    "        found_prefixes.append((p,tokenizer.decode(best_prefix)))    \n",
    "        all_losses[-1].extend(predicted_suffix_loss_batch.cpu().tolist())\n",
    "        all_naturals[-1].extend(predicted_prefix_loss_batch.cpu().tolist())\n",
    "        dataset_gold_loss.append(suffix_loss.item())\n",
    "\n",
    "    plot_beams(all_losses, all_naturals, beam_size, normalizer_temp,)#np.mean(base_naturals), np.mean(base_losses))\n",
    "    print(f'Best prefix is {tokenizer.decode(prefix_list[0])} for actual prefix {prefix} and suffix {suffix}')\n",
    "    # print(f'True prefix is:\\n{prefix} \\n\\nPredicted prefix:\\n{predicted_prefix}\\nfor suffix:\\n {suffix}')\n",
    "    # print(f'Loss for suffix given predicted prefix is {predicted_suffix_loss.item()} \\n Suffix loss for true prefix is {suffix_loss.item()}')\n",
    "    # print(f'NLL on predicted prefix is {predicted_prefix_loss.item()} \\n NLL on true prefix is {prefix_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(all_gcg_losses, all_gcg_naturals, all_losses, all_naturals, beam_size=50, gcg_hp_count=6,base_prefix_loss=np.exp(np.mean([np.log(b) for b in base_naturals])), base_suffix_loss=np.exp(-1*np.mean(dataset_gold_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pile-10k eval. Load data, backwards and forwards models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"NeelNanda/pile-10k\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"afterless/reverse-pythia-160m\")\n",
    "pairs = get_reverse_pair(dataset['train'], start_chunk_hf, tokenizer)\n",
    "print(next(pairs))\n",
    "bwd_model = GPTNeoXForCausalLM.from_pretrained(\"afterless/reverse-pythia-160m\").cuda()\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/pythia-160m\", cache_dir='/scratch/jp6263/hf/models/').cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate GCG with forward LM-guided sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 5 #None for default GCG with uniform sampling\n",
    "prefix_probability_grad_weight = 0.1\n",
    "gcg = PromptOptimizer(model, tokenizer, n_proposals=128, n_epochs=250, n_top_indices=128, prefix_loss_weight=prefix_probability_grad_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcg_tokenwise_acc = []\n",
    "gcg_loss = []\n",
    "for p,pair in enumerate(pairs):\n",
    "    if len(gcg_loss)==100: break\n",
    "    if len(pair[0])<10 or len(pair[1])<10: continue\n",
    "    prefix_loss,suffix_loss = forward_loss(model, pair, tokenizer)\n",
    "    # if suffix_loss>2.1: continue #this is around 10th percentile of losses for 170m\n",
    "    prefix, suffix = pair\n",
    "    prefix_tokens = tokenizer.encode(prefix)\n",
    "    len_prefix = len(prefix_tokens)\n",
    "    rand_prefix = rand_init(len_prefix, tokenizer)\n",
    "    optimized_string = gcg.optimize(rand_prefix, suffix, temperature=temp)\n",
    "    predicted_prefix_tokens = tokenizer.encode(optimized_string)[:len_prefix]\n",
    "    predicted_prefix = tokenizer.decode(predicted_prefix_tokens)\n",
    "    predicted_prefix_loss, predicted_suffix_loss = forward_loss(model, (predicted_prefix, suffix), tokenizer)\n",
    "    # print(f'True prefix is:\\n{prefix} \\n\\nPredicted prefix:\\n{predicted_prefix}\\nfor suffix:\\n {suffix}')\n",
    "    # print(f'Loss for suffix given predicted prefix is {predicted_suffix_loss.item()} \\n Suffix loss for true prefix is {suffix_loss.item()}')\n",
    "    # print(f'NLL on predicted prefix is {predicted_prefix_loss.item()} \\n NLL on true prefix is {prefix_loss.item()}')\n",
    "    gcg_loss.append(predicted_suffix_loss.item())\n",
    "    gcg_tokenwise_acc.append(sum([1 for i in range(len(prefix_tokens)) if prefix_tokens[i] == predicted_prefix_tokens[i]])/len(prefix_tokens))\n",
    "print(f'Average tokenwise accuracy is {sum(gcg_tokenwise_acc)/len(gcg_tokenwise_acc)}')\n",
    "print(f'Average loss is {sum(gcg_loss)/len(gcg_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 2 #None for default GCG with uniform sampling\n",
    "prefix_probability_grad_weight = 0.25\n",
    "gcg = PromptOptimizer(model, tokenizer, n_proposals=128, n_epochs=250, n_top_indices=128, prefix_loss_weight=prefix_probability_grad_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcg_tokenwise_acc = []\n",
    "gcg_loss = []\n",
    "for p,pair in enumerate(pairs):\n",
    "    if len(gcg_loss)==100: break\n",
    "    if len(pair[0])<10 or len(pair[1])<10: continue\n",
    "    prefix_loss,suffix_loss = forward_loss(model, pair, tokenizer)\n",
    "    # if suffix_loss>2.1: continue #this is around 10th percentile of losses for 170m\n",
    "    prefix, suffix = pair\n",
    "    prefix_tokens = tokenizer.encode(prefix)\n",
    "    len_prefix = len(prefix_tokens)\n",
    "    rand_prefix = rand_init(len_prefix, tokenizer)\n",
    "    optimized_string = gcg.optimize(rand_prefix, suffix, temperature=temp)\n",
    "    predicted_prefix_tokens = tokenizer.encode(optimized_string)[:len_prefix]\n",
    "    predicted_prefix = tokenizer.decode(predicted_prefix_tokens)\n",
    "    predicted_prefix_loss, predicted_suffix_loss = forward_loss(model, (predicted_prefix, suffix), tokenizer)\n",
    "    # print(f'True prefix is:\\n{prefix} \\n\\nPredicted prefix:\\n{predicted_prefix}\\nfor suffix:\\n {suffix}')\n",
    "    # print(f'Loss for suffix given predicted prefix is {predicted_suffix_loss.item()} \\n Suffix loss for true prefix is {suffix_loss.item()}')\n",
    "    # print(f'NLL on predicted prefix is {predicted_prefix_loss.item()} \\n NLL on true prefix is {prefix_loss.item()}')\n",
    "    gcg_loss.append(predicted_suffix_loss.item())\n",
    "    gcg_tokenwise_acc.append(sum([1 for i in range(len(prefix_tokens)) if prefix_tokens[i] == predicted_prefix_tokens[i]])/len(prefix_tokens))\n",
    "print(f'Average tokenwise accuracy is {sum(gcg_tokenwise_acc)/len(gcg_tokenwise_acc)}')\n",
    "print(f'Average loss is {sum(gcg_loss)/len(gcg_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load dataset probabilities and setup for reverse LM eval with p(p) normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_probs = get_token_probabilities(tokenizer)\n",
    "inverse_dataset_probs = torch.reciprocal(dataset_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_p_temp = 0\n",
    "rlm_temp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlm_tokenwise_acc = []\n",
    "rlm_loss = []\n",
    "for p,pair in enumerate(pairs):\n",
    "    if len(rlm_loss)==100: break\n",
    "    if len(pair[0])<10 or len(pair[1])<10: continue\n",
    "    prefix_loss,suffix_loss = forward_loss(model, pair, tokenizer)\n",
    "    # if suffix_loss>2.1: continue #this is around 10th percentile of losses for 170m\n",
    "    prefix, suffix = pair\n",
    "    prefix_tokens = tokenizer.encode(prefix)\n",
    "    len_prefix = len(prefix_tokens)\n",
    "    predicted_prefix = reverse_normalized_generate(bwd_model, tokenizer, suffix, len_prefix, inverse_dataset_probs**dataset_p_temp, temperature=rlm_temp) \n",
    "    predicted_prefix_tokens = tokenizer.encode(predicted_prefix)[:len_prefix]\n",
    "    predicted_prefix = tokenizer.decode(predicted_prefix_tokens)\n",
    "\n",
    "    predicted_prefix_loss, predicted_suffix_loss = forward_loss(model, (predicted_prefix, suffix), tokenizer)\n",
    "    # print(f'True prefix is:\\n{prefix} \\n\\nPredicted prefix:\\n{predicted_prefix}\\nfor suffix:\\n {suffix}')\n",
    "    # print(f'Loss for suffix given predicted prefix is {predicted_suffix_loss.item()} \\n Suffix loss for true prefix is {suffix_loss.item()}')\n",
    "    # print(f'NLL on predicted prefix is {predicted_prefix_loss.item()} \\n NLL on true prefix is {prefix_loss.item()}')\n",
    "\n",
    "    rlm_tokenwise_acc.append(sum([1 for i in range(len(prefix_tokens)) if prefix_tokens[i] == predicted_prefix_tokens[i]])/len(prefix_tokens))\n",
    "    rlm_loss.append(predicted_suffix_loss.item())\n",
    "\n",
    "print(f'Average tokenwise accuracy is {sum(rlm_tokenwise_acc)/len(rlm_tokenwise_acc)}')\n",
    "print(f'Average loss is {sum(rlm_loss)/len(rlm_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate rejection sampling of RLM (no normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlm_tokenwise_acc = []\n",
    "rlm_loss = []\n",
    "rlm_best_tokenwise_acc = []\n",
    "rlm_best_loss = []\n",
    "all_losses = []\n",
    "rlm_greedy_loss = []\n",
    "all_naturals = []\n",
    "greedy_natural = []\n",
    "pile_prefix_loss = []\n",
    "\n",
    "dataset_gold_loss = []\n",
    "dataset_p_temp = 0\n",
    "rlm_temp=0.01\n",
    "rejection_sample = 100\n",
    "eval_size=100\n",
    "\n",
    "for p,pair in enumerate(tqdm(pairs)):\n",
    "    if len(rlm_loss)==eval_size: break\n",
    "    if len(pair[0])<10 or len(pair[1])<10: continue\n",
    "    prefix_loss,suffix_loss = forward_loss(model, pair, tokenizer)\n",
    "    # if suffix_loss>2.1: continue #this is around 10th percentile of losses for 170m\n",
    "    prefix, suffix = pair\n",
    "    prefix_tokens = tokenizer.encode(prefix)\n",
    "    len_prefix = len(prefix_tokens)\n",
    "\n",
    "    min_loss, min_prefix = float('inf'), None\n",
    "    all_losses.append([])\n",
    "    all_naturals.append([])\n",
    "    for t in range(rejection_sample):\n",
    "        predicted_prefix = reverse_normalized_generate(bwd_model, tokenizer, suffix, len_prefix, None, temperature=rlm_temp) \n",
    "        predicted_prefix_tokens = tokenizer.encode(predicted_prefix)[:len_prefix]\n",
    "        predicted_prefix = tokenizer.decode(predicted_prefix_tokens)\n",
    "        predicted_prefix_loss, predicted_suffix_loss = forward_loss(model, (predicted_prefix, suffix), tokenizer)\n",
    "        all_losses[-1].append(predicted_suffix_loss.item())\n",
    "        all_naturals[-1].append(predicted_prefix_loss.item())\n",
    "        if predicted_suffix_loss < min_loss:\n",
    "            min_loss = predicted_suffix_loss\n",
    "            min_prefix = predicted_prefix\n",
    "            min_prefix_tokens = predicted_prefix_tokens\n",
    "    # print(f'True prefix is:\\n{prefix} \\n\\nPredicted prefix:\\n{min_prefix}\\nfor suffix:\\n {suffix}')\n",
    "    # print(f'Loss for suffix given predicted prefix is {min_loss.item()} \\n Suffix loss for true prefix is {suffix_loss.item()}')\n",
    "    # print(f'NLL on predicted prefix is {predicted_prefix_loss.item()} \\n NLL on true prefix is {prefix_loss.item()}')\n",
    "\n",
    "    #Now get greedy loss as baseline\n",
    "\n",
    "    predicted_prefix = reverse_normalized_generate(bwd_model, tokenizer, suffix, len_prefix, None, temperature=0) \n",
    "    predicted_prefix_tokens = tokenizer.encode(predicted_prefix)[:len_prefix]\n",
    "    predicted_prefix = tokenizer.decode(predicted_prefix_tokens)\n",
    "    greedy_prefix_loss, greedy_loss = forward_loss(model, (predicted_prefix, suffix), tokenizer)\n",
    "    \n",
    "    pile_prefix_loss.append(prefix_loss.item())\n",
    "    greedy_natural.append(greedy_prefix_loss.item())\n",
    "    dataset_gold_loss.append(suffix_loss.item())\n",
    "    rlm_tokenwise_acc.append(sum([1 for i in range(len(prefix_tokens)) if prefix_tokens[i] == predicted_prefix_tokens[i]])/len(prefix_tokens))\n",
    "    rlm_loss.append(predicted_suffix_loss.item())\n",
    "    rlm_best_tokenwise_acc.append(sum([1 for i in range(len(prefix_tokens)) if prefix_tokens[i] == min_prefix_tokens[i]])/len(prefix_tokens))\n",
    "    rlm_best_loss.append(min_loss.item())\n",
    "    rlm_greedy_loss.append(greedy_loss.item())\n",
    "\n",
    "print(f'Average tokenwise accuracy is {sum(rlm_tokenwise_acc)/len(rlm_tokenwise_acc)}')\n",
    "print(f'Average loss is {sum(rlm_loss)/len(rlm_loss)}')\n",
    "print(f'Average dataset gold loss is {sum(dataset_gold_loss)/len(dataset_gold_loss)}')\n",
    "print(f'Best tokenwise accuracy is {sum(rlm_best_tokenwise_acc)/len(rlm_best_tokenwise_acc)}')\n",
    "print(f'Best loss is {sum(rlm_best_loss)/len(rlm_best_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Initialization\n",
    "Ns = range(1, rejection_sample)\n",
    "mean_best_of_N_loss = []\n",
    "\n",
    "for N in Ns:\n",
    "    best_of_N_loss = [min(single_list[:N]) for single_list in all_losses]\n",
    "    mean_best_of_N_loss.append(np.mean(best_of_N_loss))\n",
    "\n",
    "plt.axhline(y=sum(dataset_gold_loss)/len(dataset_gold_loss), color='r', linestyle='--', label='Loss given true prefix')\n",
    "plt.axhline(y=sum(rlm_greedy_loss)/len(rlm_greedy_loss), color='g', linestyle='--', label='Loss given greedy decode prefix')\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(Ns, mean_best_of_N_loss, marker='o')\n",
    "plt.xlabel('Number of Rejection Sampling Steps')\n",
    "plt.ylabel('Arithmetic Mean of Best-of-N Loss')\n",
    "plt.title('Arithmetic Mean of Best-of-N Loss vs Rejection Sampling Steps')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "mean_greedy_natural = sum(greedy_natural)/len(greedy_natural)\n",
    "mean_greedy_loss = sum(rlm_greedy_loss)/len(rlm_greedy_loss)\n",
    "pile_suffix_loss = sum(dataset_gold_loss)/len(dataset_gold_loss)\n",
    "pile_prefix_natural = sum(pile_prefix_loss)/len(pile_prefix_loss)\n",
    "\n",
    "Ns = range(1, rejection_sample)\n",
    "mean_natural_loss = []\n",
    "best_of_N_loss = []\n",
    "\n",
    "for N in Ns:\n",
    "    mean_natural_loss.append(np.mean([np.mean(single_list[:N]) for single_list in all_naturals]))  # Assuming all_naturals is a list of lists\n",
    "    best_of_N_loss.append(np.mean([min(single_list[:N]) for single_list in all_losses]))  # Assuming all_losses is a list of lists\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(mean_natural_loss, best_of_N_loss, marker='o', label='Best-of-N')\n",
    "plt.plot([mean_greedy_natural], [mean_greedy_loss], marker='x', linestyle='', color='red', label='Greedy')\n",
    "plt.plot([pile_prefix_natural], [pile_suffix_loss], marker='s', linestyle='', color='green', label='Pile')\n",
    "plt.xlabel('Arithmetic Mean of NLL of forwards LM on Prefix')\n",
    "plt.ylabel('Best-of-N Suffix Loss')\n",
    "plt.title('Best-of-N Suffix Loss vs Arithmetic Mean of NLL of forwards LM on Prefix')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
